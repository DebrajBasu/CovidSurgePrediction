{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import pacf \n",
    "from statsmodels.tsa.stattools import acf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn. __version__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = (1 if type(data) is list else data.shape[1])\n",
    "    df = DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg.values\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test, :], data[-n_test:, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get the list of all input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_list = list(l for l in os.listdir() if ('covid_ai_model_input_data' in l) and ('test' not in l) )\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict D1_COVID_NEW_ADM_CNT Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import datetime as dt, timedelta\n",
    "# import forestci as fci\n",
    "# features_to_add =['POSITIVITY_RATE_MEAN', 'COVID_MED_SURG_NO_HFNC_CNT_M', 'COVID_MED_SURG_CNT_M',\t'COVID_NEW_ADM_MEAN',\\\n",
    "#                   'COVID_POS_PT_CNT_EVER',\t'COVID_PT_CNT_M',\t'COVID_PT_CNT_MIDNIGHT_MEAN','INDX_UCDH_POSITIVITY_RATE',\\\n",
    "#                  'INDX_UCDH_POS_PT_CNT', 'COVID_NEW_ADM_CNT', 'INDX_POS_PT_ALL_ADM_CNT', 'COVID_DISCHARGE_MEAN',\t'COVID_ICU_NO_VENT_CNT_M',\\\n",
    "#                   'COVID_ACTIVE_DNR_CNT_M',\t'OUTREACH_POSITIVITY_MEAN', 'TESTED_PT_CNT_MEAN', 'INDX_POS_PT_NEW_ADM_CNT', \\\n",
    "#                   'COVID_DISCHARGE_CNT']\n",
    "# # features_to_add =[\"POSITIVITY_RATE_MEAN\"]\n",
    "feature_to_predict = ['D1_COVID_NEW_ADM_CNT']\n",
    "lag_new_D1 =2\n",
    "import os\n",
    "file_list = list(l for l in os.listdir() if ('covid_ai_model_input_data' in l) and ('test' not in l) )\n",
    "for f in file_list:\n",
    "    df = pd.read_csv(f)\n",
    "    df['SOURCE_DATA_DATE'] = df['SOURCE_DATA_DATE'].astype('datetime64[ns]')\n",
    "\n",
    "    # # transform the time series data into supervised learning\n",
    "    ## ------------------------------------------------\n",
    "    index_date_sub1 = df['SOURCE_DATA_DATE'].iloc[-2]\n",
    "    df_validation = df[df['SOURCE_DATA_DATE'] <= index_date_sub1 ].reset_index(drop= True)\n",
    "    data_multi =df_validation[feature_to_predict].values\n",
    "    #data =(df_validation['COVID_MED_SURG_NO_HFNC_PCT_M'].values)/100\n",
    "\n",
    "    # data = data.reshape(-1,1)\n",
    "    data_ML = pd.DataFrame()\n",
    "    for r in range(data_multi.shape[1]):\n",
    "        data_current = data_multi[:,r].reshape(-1,1)\n",
    "    #     data = series_to_supervised(data_current, n_in=lag_D2+1)\n",
    "        data = series_to_supervised(data_current, n_in=lag_new_D1)\n",
    "    #     if r == data_multi.shape[1]-1:\n",
    "    #         data = data[:,1:]\n",
    "    #     if r != data_test.shape[1]-1:\n",
    "    #         data = data[-lag-2:,-1] ## updated to make 5 (lag of 3 +2)past days \n",
    "    #     else:\n",
    "    #         data = data[-lag:,-1]\n",
    "\n",
    "        data_ML = pd.concat([data_ML, pd.DataFrame(data)], axis= 1)\n",
    "\n",
    "    train_current = data_ML.values\n",
    "    # split into input and output columns\n",
    "    # trainX, trainy = train_current[:-1, :-1], train_current[:-1, -1]\n",
    "    trainX, trainy = train_current[:, :-1], train_current[:, -1]\n",
    "    # # fit model\n",
    "\n",
    "    # tscv = TimeSeriesSplit(test_size = 1, n_splits= 5,gap =1)\n",
    "    tscv = TimeSeriesSplit(test_size = 1, n_splits= 30)  \n",
    "\n",
    "    alpha = 0.95\n",
    "    param_grid = {'n_estimators':[50, 100, 200, 300, 500],'learning_rate':[0.01, 0.1,1],\\\n",
    "                                   'max_depth':[1,2,4]}\n",
    "    clf = GradientBoostingRegressor(loss='quantile', alpha=alpha, random_state= 1)\n",
    "    regression_model = GridSearchCV(clf, param_grid= param_grid , \\\n",
    "                                      cv = tscv, scoring= ['neg_mean_squared_error'],refit= 'neg_mean_squared_error', n_jobs=-1)\n",
    "    # # regression_model = GridSearchCV(clf, param_grid= param_grid , \\\n",
    "    # #                                 cv = tscv, scoring= ['neg_mean_squared_error'],refit= 'neg_mean_squared_error', n_jobs=-1)\n",
    "    # #     regression_model = GridSearchCV(clf, param_grid= param_grid ,cv = tscv, n_jobs=-1)\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    row = trainy[-lag_new_D1:]\n",
    "    # Make the prediction on the meshed x-axis\n",
    "    y_upper = regression_model.predict([row])\n",
    "    print('Upper quantile: {}'.format(y_upper))\n",
    "\n",
    "    clf.set_params(alpha=1.0 - alpha)\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    # Make the prediction on the meshed x-axis\n",
    "    y_lower = regression_model.predict([row])\n",
    "\n",
    "    print('Lower quantile: {}'.format(y_lower))\n",
    "\n",
    "    clf.set_params(loss='ls')\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    # # Make the prediction on the meshed x-axis\n",
    "    y_pred = regression_model.predict([row])\n",
    "    print('Predicted: {}'.format(y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Predict D1_COVID_PT_CNT_M univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import datetime as dt, timedelta\n",
    "\n",
    "# features_to_add =[\"POSITIVITY_RATE_MEAN\"]\n",
    "feature_to_predict = ['D1_COVID_PT_CNT_M']\n",
    "lag_D1 =2\n",
    "# lag_D1 =3\n",
    "for f in file_list:\n",
    "    df = pd.read_csv(f)\n",
    "    df['SOURCE_DATA_DATE'] = df['SOURCE_DATA_DATE'].astype('datetime64[ns]')\n",
    "\n",
    "    # # transform the time series data into supervised learning\n",
    "    ## ------------------------------------------------\n",
    "    index_date_sub1 = df['SOURCE_DATA_DATE'].iloc[-2]\n",
    "    #datetime_object = datetime.strptime(datetime_str, '%m-%d-%y')\n",
    "    # df_validation = df[df['SOURCE_DATA_DATE'] <= datetime_object ].reset_index(drop= True)\n",
    "    df_validation = df[df['SOURCE_DATA_DATE'] <= index_date_sub1 ].reset_index(drop= True)\n",
    "    data_multi =df_validation[feature_to_predict].values\n",
    "    #data =(df_validation['COVID_MED_SURG_NO_HFNC_PCT_M'].values)/100\n",
    "\n",
    "    # data = data.reshape(-1,1)\n",
    "    data_ML = pd.DataFrame()\n",
    "    for r in range(data_multi.shape[1]):\n",
    "        data_current = data_multi[:,r].reshape(-1,1)\n",
    "        data = series_to_supervised(data_current, n_in=lag_D1)\n",
    "    #     if r != data_multi.shape[1]-1:\n",
    "    #         data = data[:,:-1]\n",
    "\n",
    "        data_ML = pd.concat([data_ML, pd.DataFrame(data)], axis= 1)\n",
    "\n",
    "    train_current = data_ML.values\n",
    "    # split into input and output columns\n",
    "    # trainX, trainy = train_current[:-1, :-1], train_current[:-1, -1]\n",
    "    trainX, trainy = train_current[:, :-1], train_current[:, -1]\n",
    "    # # fit model\n",
    "\n",
    "    # tscv = TimeSeriesSplit(test_size = 1, n_splits= 5,gap =1)\n",
    "    tscv = TimeSeriesSplit(test_size = 1, n_splits= 30)\n",
    "\n",
    "    alpha = 0.95\n",
    "    param_grid = {'n_estimators':[50, 100, 200, 300, 500],'learning_rate':[0.01, 0.1,1],\\\n",
    "                                   'max_depth':[1,2,4]}\n",
    "    clf = GradientBoostingRegressor(loss='quantile', alpha=alpha, random_state= 1)\n",
    "    regression_model = GridSearchCV(clf, param_grid= param_grid , \\\n",
    "                                      cv = tscv, scoring= ['neg_mean_squared_error'],refit= 'neg_mean_squared_error', n_jobs=-1)\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    row = trainy[-lag_D1:]\n",
    "    # Make the prediction on the meshed x-axis\n",
    "    y_upper = regression_model.predict([row])\n",
    "    print('Upper quantile: {}'.format(y_upper))\n",
    "\n",
    "    clf.set_params(alpha=1.0 - alpha)\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    # Make the prediction on the meshed x-axis\n",
    "    y_lower = regression_model.predict([row])\n",
    "\n",
    "    print('Lower quantile: {}'.format(y_lower))\n",
    "\n",
    "    clf.set_params(loss='ls')\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    # # Make the prediction on the meshed x-axis\n",
    "    y_pred = regression_model.predict([row])\n",
    "    print('Predicted: {}'.format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Predict D2_COVID_PT_CNT_M with univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import datetime as dt, timedelta\n",
    "feature_to_predict = ['D2_COVID_PT_CNT_M']\n",
    "lag_D2 =2\n",
    "for f in file_list:\n",
    "    df = pd.read_csv(f)\n",
    "    #df = pd.read_csv('covid_ai_model_input_data-2021-01-26.csv')\n",
    "    df['SOURCE_DATA_DATE'] = df['SOURCE_DATA_DATE'].astype('datetime64[ns]')\n",
    "    # removing one row of old data\n",
    "    #df[1:].reset_index(drop= True, inplace = True)\n",
    "\n",
    "    # # transform the time series data into supervised learning\n",
    "    ## ------------------------------------------------\n",
    "    index_date_sub2 = df['SOURCE_DATA_DATE'].iloc[-3]\n",
    "    # datetime_object = datetime.strptime(datetime_str, '%m-%d-%y')\n",
    "    # df_validation = df[df['SOURCE_DATA_DATE'] <= datetime_object ].reset_index(drop= True)\n",
    "    df_validation = df[df['SOURCE_DATA_DATE'] <= index_date_sub2 ].reset_index(drop= True)\n",
    "    #data_multi =df_validation[features_to_add+ feature_to_predict].values\n",
    "    data_multi =df_validation[feature_to_predict].values\n",
    "    #data =(df_validation['COVID_MED_SURG_NO_HFNC_PCT_M'].values)/100\n",
    "\n",
    "    # data = data.reshape(-1,1)\n",
    "    data_ML = pd.DataFrame()\n",
    "    for r in range(data_multi.shape[1]):\n",
    "        data_current = data_multi[:,r].reshape(-1,1)\n",
    "        # data = series_to_supervised(data_current, n_in=lag_D2+1)\n",
    "        data = series_to_supervised(data_current, n_in=lag_D2)\n",
    "\n",
    "    \n",
    "        data_ML = pd.concat([data_ML, pd.DataFrame(data)], axis= 1)\n",
    "\n",
    "    train_current = data_ML.values\n",
    "    # split into input and output columns\n",
    "    # trainX, trainy = train_current[:-1, :-1], train_current[:-1, -1]\n",
    "    trainX, trainy = train_current[:, :-1], train_current[:, -1]\n",
    "    # fit model\n",
    "\n",
    "    # tscv = TimeSeriesSplit(test_size = 1, n_splits= 5,gap =1)\n",
    "    tscv = TimeSeriesSplit(test_size = 1, n_splits= 30)\n",
    "\n",
    "    alpha = 0.95\n",
    "    param_grid = {'n_estimators':[50, 100, 200, 300, 500],'learning_rate':[0.01, 0.1,1],\\\n",
    "                                   'max_depth':[1,2,4]}\n",
    "    clf = GradientBoostingRegressor(loss='quantile', alpha=alpha, random_state= 1)\n",
    "    regression_model = GridSearchCV(clf, param_grid= param_grid , \\\n",
    "                                      cv = tscv, scoring= ['neg_mean_squared_error'],refit= 'neg_mean_squared_error', n_jobs=-1)\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    row = trainy[-lag_D2:]\n",
    "    # Make the prediction on the meshed x-axis\n",
    "    y_upper = regression_model.predict([row])\n",
    "    print('Upper quantile: {}'.format(y_upper))\n",
    "    PTS_D2_COVID_CENSUS_PI_UPPER = y_upper[0]\n",
    "\n",
    "    clf.set_params(alpha=1.0 - alpha)\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    # Make the prediction on the meshed x-axis\n",
    "    y_lower = regression_model.predict([row])\n",
    "    print('Lower quantile: {}'.format(y_lower))\n",
    "    PTS_D2_COVID_CENSUS_PI_LOWER = y_lower[0]\n",
    "\n",
    "    clf.set_params(loss='ls')\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    # # Make the prediction on the meshed x-axis\n",
    "    y_pred = regression_model.predict([row])\n",
    "    print('Predicted: {}'.format(y_pred))\n",
    "    PTS_D2_COVID_CENSUS = y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Predict D2_COVID_NEW_ADM_CNT with univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import datetime as dt, timedelta\n",
    "\n",
    "feature_to_predict = ['D2_COVID_NEW_ADM_CNT']\n",
    "lag_D2 =2\n",
    "\n",
    "for f in ['covid_ai_model_input_data.csv']:\n",
    "    df = pd.read_csv(f)\n",
    "    #df = pd.read_csv('covid_ai_model_input_data-2021-01-26.csv')\n",
    "    df['SOURCE_DATA_DATE'] = df['SOURCE_DATA_DATE'].astype('datetime64[ns]')\n",
    "    # removing one row of old data\n",
    "    #df[1:].reset_index(drop= True, inplace = True)\n",
    "\n",
    "    # # transform the time series data into supervised learning\n",
    "    ## ------------------------------------------------\n",
    "    index_date_sub2 = df['SOURCE_DATA_DATE'].iloc[-3]\n",
    "    # datetime_object = datetime.strptime(datetime_str, '%m-%d-%y')\n",
    "    # df_validation = df[df['SOURCE_DATA_DATE'] <= datetime_object ].reset_index(drop= True)\n",
    "    df_validation = df[df['SOURCE_DATA_DATE'] <= index_date_sub2 ].reset_index(drop= True)\n",
    "    #data_multi =df_validation[features_to_add+ feature_to_predict].values\n",
    "    data_multi =df_validation[feature_to_predict].values\n",
    "    #data =(df_validation['COVID_MED_SURG_NO_HFNC_PCT_M'].values)/100\n",
    "\n",
    "    # data = data.reshape(-1,1)\n",
    "    data_ML = pd.DataFrame()\n",
    "    for r in range(data_multi.shape[1]):\n",
    "        data_current = data_multi[:,r].reshape(-1,1)\n",
    "    #     data = series_to_supervised(data_current, n_in=lag_D2+1)\n",
    "        data = series_to_supervised(data_current, n_in=lag_D2)\n",
    "    #     if r == data_multi.shape[1]-1:\n",
    "    #         data = data[:,1:]\n",
    "    #     if r != data_test.shape[1]-1:\n",
    "    #         data = data[-lag-2:,-1] ## updated to make 5 (lag of 3 +2)past days \n",
    "    #     else:\n",
    "    #         data = data[-lag:,-1]\n",
    "\n",
    "        data_ML = pd.concat([data_ML, pd.DataFrame(data)], axis= 1)\n",
    "\n",
    "    train_current = data_ML.values\n",
    "    # split into input and output columns\n",
    "    # trainX, trainy = train_current[:-1, :-1], train_current[:-1, -1]\n",
    "    trainX, trainy = train_current[:, :-1], train_current[:, -1]\n",
    "    # # fit model\n",
    "\n",
    "    # tscv = TimeSeriesSplit(test_size = 1, n_splits= 5,gap =1)\n",
    "    tscv = TimeSeriesSplit(test_size = 1, n_splits= 30)\n",
    "\n",
    "    # Create the current data set to make the prediction based on the trained model\n",
    "\n",
    "    # # datetime_str = '01-09-21'\n",
    "    # index_date = df['SOURCE_DATA_DATE'].iloc[-1]\n",
    "    # # datetime_object = datetime.strptime(datetime_str, '%m-%d-%y')\n",
    "    # # df_test = df[df['SOURCE_DATA_DATE'] <= datetime_object ].reset_index(drop= True)\n",
    "    # df_test = df[df['SOURCE_DATA_DATE'] <= index_date ].reset_index(drop= True)\n",
    "    # data_test =df_test[features_to_add+ feature_to_predict].values\n",
    "\n",
    "    # data_prediction = pd.DataFrame()\n",
    "    # for r in range(data_test.shape[1]):\n",
    "    #     data_current = data_test[:,r].reshape(-1,1)\n",
    "    #     data = series_to_supervised(data_current, n_in=lag_D2)\n",
    "    # #     print(data.shape)\n",
    "    #     if r != data_test.shape[1]-1:\n",
    "    #         data = data[-lag_D2-2:,-1] ## updated to make 5 (lag of 3 +2)past days \n",
    "    #     else:\n",
    "    #         data = data[-lag_D2:,-1]\n",
    "\n",
    "\n",
    "    #     data_prediction = pd.concat([data_prediction, pd.DataFrame(data)], axis= 0)\n",
    "\n",
    "    # # row  = data[-3:].flatten()\n",
    "    # row = data_prediction.values.flatten()\n",
    "\n",
    "    alpha = 0.95\n",
    "    param_grid = {'n_estimators':[50, 100, 200, 300, 500],'learning_rate':[0.01, 0.1,1],\\\n",
    "                                   'max_depth':[1,2,4]}\n",
    "    clf = GradientBoostingRegressor(loss='quantile', alpha=alpha, random_state= 1)\n",
    "    regression_model = GridSearchCV(clf, param_grid= param_grid , \\\n",
    "                                      cv = tscv, scoring= ['neg_mean_squared_error'],refit= 'neg_mean_squared_error', n_jobs=-1)\n",
    "    # # regression_model = GridSearchCV(clf, param_grid= param_grid , \\\n",
    "    # #                                 cv = tscv, scoring= ['neg_mean_squared_error'],refit= 'neg_mean_squared_error', n_jobs=-1)\n",
    "    # #     regression_model = GridSearchCV(clf, param_grid= param_grid ,cv = tscv, n_jobs=-1)\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    row = trainy[-lag_D2:]\n",
    "    # Make the prediction on the meshed x-axis\n",
    "    y_upper = regression_model.predict([row])\n",
    "    print('Upper quantile: {}'.format(y_upper))\n",
    "\n",
    "    clf.set_params(alpha=1.0 - alpha)\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    # Make the prediction on the meshed x-axis\n",
    "    y_lower = regression_model.predict([row])\n",
    "\n",
    "    print('Lower quantile: {}'.format(y_lower))\n",
    "\n",
    "    clf.set_params(loss='ls')\n",
    "    regression_model.fit(trainX, trainy)\n",
    "\n",
    "    # # Make the prediction on the meshed x-axis\n",
    "    y_pred = regression_model.predict([row])\n",
    "    print('Predicted: {}'.format(y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# # # # # make a one-step prediction\n",
    "# # yhat = regression_model.predict(asarray([row]))\n",
    "\n",
    "# # print('Input: %s, Predicted: %.3f' % (row, yhat[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
